{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **LinkedIn Post Retrieval**\n",
        "\n",
        "This Python script leverages the LinkedIn API to fetch posts from a  Showcase Page. The script is thoughtfully designed to manage pagination efficiently, ensuring the retrieval of all available posts through successive GET requests. By parsing the LinkedIn API responses, the script extracts crucial details such as post content and creation time. The extracted information is then structured into a Pandas DataFrame, presenting a tabular format that facilitates straightforward analysis.\n",
        "\n",
        "\n",
        "Key components of the script include:\n",
        "\n",
        "\n",
        "**Access Token and API Endpoint:** Users must replace placeholders with their actual LinkedIn API access token and Showcase Page ID. These credentials are vital for authentication and specifying the target organization or Showcase Page.\n",
        "\n",
        "**API Request:** The script orchestrates a series of GET requests to the LinkedIn API, navigating through paginated responses to compile a comprehensive set of posts.\n",
        "\n",
        "**Data Extraction:** Response data undergoes parsing to selectively extract pertinent details, including post content and creation time, from the intricate nested structure of the API response.\n",
        "\n",
        "**DataFrame Creation:** The extracted data is meticulously organized into a Pandas DataFrame, featuring distinct columns for 'Post Content' and 'Creation Time'.\n",
        "\n",
        "**Print Output:** The script culminates in printing the resulting DataFrame to the console, furnishing a neatly formatted tabular view of the post data. Additionally, the total number of retrieved posts is displayed.\n",
        "\n",
        "\n",
        "In essence, this script establishes a robust foundation for the exploration and analysis of LinkedIn posts, offering a systematic and structured approach for users keen on deriving insights from their LinkedIn data.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QCukKSKjpB3v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iluh1yv4mxd3"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# Replace 'YOUR_ACCESS_TOKEN' with the actual access token obtained through LinkedIn's API authentication process\n",
        "access_token = 'YOUR_ACCESS_TOKEN'\n",
        "\n",
        "# Replace 'SHOWCASE_PAGE_ID' with the actual Showcase Page ID\n",
        "showcase_page_id = 'SHOWCASE_PAGE_ID'\n",
        "\n",
        "# Define the API endpoint for retrieving posts for a specific organization or Showcase Page\n",
        "api_url = f'API endpoint:{showcase_page_id}'\n",
        "\n",
        "# Set up the headers with the access token\n",
        "headers = {\n",
        "    'Authorization': f'Bearer {access_token}',\n",
        "}\n",
        "\n",
        "try:\n",
        "    # Initialize variables\n",
        "    all_posts = []\n",
        "    start = 0\n",
        "    count = 10  # You can adjust the count based on the desired number of posts per request\n",
        "\n",
        "    while True:\n",
        "        # Make a GET request to the LinkedIn API to retrieve posts\n",
        "        params = {'start': start, 'count': count}\n",
        "        response = requests.get(api_url, headers=headers, params=params)\n",
        "\n",
        "        # Check if the request was successful\n",
        "        if response.status_code == 200:\n",
        "            # Parse and process the response data to get post information\n",
        "            posts_data = response.json().get('elements', [])\n",
        "\n",
        "            # Add the posts to the list\n",
        "            all_posts.extend(posts_data)\n",
        "\n",
        "            # Check if there are more pages and update the start value\n",
        "            pagination = response.json().get('paging', {})\n",
        "            start = pagination.get('start', 0) + count\n",
        "\n",
        "            if start >= pagination.get('total', 0):\n",
        "                break  # Exit the loop if all posts have been retrieved\n",
        "\n",
        "        else:\n",
        "            print(f\"Error fetching posts: {response.status_code} - {response.text}\")\n",
        "            break  # Exit the loop in case of an error\n",
        "\n",
        "    # Create a DataFrame from the extracted data\n",
        "    data = {'Post Content': [], 'Creation Time': []}\n",
        "    for post in all_posts:\n",
        "        # Extract 'text' from nested structure\n",
        "        post_text = post.get('text', {}).get('text', '')\n",
        "\n",
        "        # Extract 'time' from nested structure\n",
        "        creation_date = post.get('created', {}).get('time', '') or post.get('creationDateTime', {}).get('time', '')\n",
        "\n",
        "        data['Post Content'].append(post_text)\n",
        "        data['Creation Time'].append(creation_date)\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Print the DataFrame\n",
        "    print(df)\n",
        "\n",
        "    # Print the count of all posts\n",
        "    print(f\"Total number of posts: {len(all_posts)}\")\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Request Exception: {e}\")\n"
      ]
    }
  ]
}